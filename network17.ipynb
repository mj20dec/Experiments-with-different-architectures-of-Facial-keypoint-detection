{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2140, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "df = pd.read_csv(\"training.csv\")\n",
    "df.dropna(inplace=True)\n",
    "sample = df.shape[0]\n",
    "df[\"Image\"] = df[\"Image\"].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "x = np.vstack(np.array(df[\"Image\"])).reshape(sample, 96, 96)\n",
    "#normaliation done\n",
    "x = x/255\n",
    "y = df.drop(columns=\"Image\").as_matrix()\n",
    "print (x.shape)\n",
    "\n",
    "def image_points(ser):\n",
    "    plt.imshow(ser[\"Image\"].reshape(96, 96), cmap=\"gray\")\n",
    "    ser = ser.values[0:30]\n",
    "    for i in range(15):\n",
    "        plt.scatter(ser[2*i], ser[2*i+1], c='r', s=40)\n",
    "\n",
    "def image_x_y(x, y):\n",
    "    plt.imshow(x, cmap=\"gray\")\n",
    "    for i in range(15):\n",
    "        plt.scatter(y[2*i], y[2*i+1], c='r', s=40)\n",
    "\n",
    "def mir_y(input_y):\n",
    "    temp = np.copy(input_y)\n",
    "    for i in range(30):\n",
    "        if (i+1)%2:\n",
    "            temp[i] = 96 - input_y[i]\n",
    "    return temp\n",
    "\n",
    "def HistogramStretching(image):\n",
    "    # a, b = min(image), max(image)\n",
    "    a, b = np.percentile(image, 5), np.percentile(image, 95)\n",
    "    l, u = 0, 1\n",
    "    const = 1.0*(b*l - a*u)/(b - a)\n",
    "    k = 1.0*(u-l)/(b-a)\n",
    "    return [k*p+const for p in image]\n",
    "\n",
    "def rotate_p(x,y,a, x0=48, y0=48):\n",
    "    x2 = ((x - x0) * np.cos(a)) - ((y - y0) * np.sin(a)) + x0\n",
    "    y2 = ((x - x0) * np.sin(a)) + ((y - y0) * np.cos(a)) + y0\n",
    "    return (x2, y2)\n",
    "\n",
    "def rotate_img(img, a):\n",
    "    M = cv2.getRotationMatrix2D((48,48),a,1)\n",
    "    dst = np.copy(cv2.warpAffine(img,M,(96,96)))\n",
    "    return dst\n",
    "\n",
    "def rotate_yp(n, a):\n",
    "    t = []\n",
    "    for i in range(15):\n",
    "        nx, ny = rotate_p(n[2*i], n[2*i+1], a)\n",
    "        t.append(nx)\n",
    "        t.append(ny)\n",
    "    return t\n",
    "\n",
    "def rotate(x, y, a):\n",
    "    # a in degrees\n",
    "    nimg = rotate_img(x, a)\n",
    "    ny = rotate_yp(y, -1*(np.pi/6)*(a/30.0))\n",
    "    return (nimg, ny)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2140, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "nx = []\n",
    "for i in x:\n",
    "    nx.append(cv2.resize(i, (32, 32)))\n",
    "x = np.array(nx)\n",
    "print x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fde7f013990>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fde88e63590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(x[1], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 96)\n"
     ]
    }
   ],
   "source": [
    "print resized_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 96, 96) (200, 30)\n"
     ]
    }
   ],
   "source": [
    "x = x[:200]\n",
    "y = y[:200]\n",
    "sample = 200\n",
    "print x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((600, 96, 96), (600, 30))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#q = df.loc[randint(0, df.shape[0])]\n",
    "#image_points(q)\n",
    "x_translate = []\n",
    "y_translate = []\n",
    "for i in range(x.shape[0]):\n",
    "    min_px = 95\n",
    "    max_px = 2\n",
    "    min_py = 95\n",
    "    max_py = 2\n",
    "    for p in range(15):\n",
    "        min_px = min(min_px, y[i][2*p])\n",
    "        max_px = max(max_px, y[i][2*p])\n",
    "        min_py = min(min_py, y[i][2*p+1])\n",
    "        max_py = max(max_py, y[i][2*p+1])\n",
    "    \n",
    "    max_py = max_py-1\n",
    "    max_px = max_px-1\n",
    "    min_px = min_px+1\n",
    "    min_py = min_py+1\n",
    "    \n",
    "    for _ in range(4):\n",
    "        ht = np.random.randint(2)\n",
    "        vt = np.random.randint(2)\n",
    "\n",
    "        if ht==0:\n",
    "            mx = -1*np.random.randint(min_px)\n",
    "        else:\n",
    "            mx = np.random.randint(96-max_px)\n",
    "\n",
    "        if vt==0:\n",
    "            my = -1*np.random.randint(min_py)\n",
    "        else:\n",
    "            #print (max_py)\n",
    "            my = np.random.randint(96-max_py)\n",
    "\n",
    "        M = np.float32([[1, 0, mx], [0, 1, my]])\n",
    "        x_translate.append(np.copy(cv2.warpAffine(x[i], M, (96, 96))))\n",
    "        \n",
    "        #plt.imshow(cv2.warpAffine(x[i], M, (96, 96)), cmap='gray')\n",
    "\n",
    "        y_t = np.copy(y[i])\n",
    "        for p in range(15):\n",
    "            y_t[2*p] = y[i][2*p]+mx\n",
    "            y_t[2*p+1] = y[i][2*p+1]+my\n",
    "\n",
    "        y_translate.append(y_t)\n",
    "\n",
    "x_rotate = []\n",
    "y_rotate = []\n",
    "for i in range(x.shape[0]):\n",
    "    for _ in range(4):\n",
    "        a = np.random.randint(-90,90)\n",
    "        \n",
    "        nx, ny = rotate(x[i], y[i], a)\n",
    "        \n",
    "        min_px = 95\n",
    "        max_px = 2\n",
    "        min_py = 95\n",
    "        max_py = 2\n",
    "        for p in range(15):\n",
    "            min_px = min(min_px, ny[2*p])\n",
    "            max_px = max(max_px, ny[2*p])\n",
    "            min_py = min(min_py, ny[2*p+1])\n",
    "            max_py = max(max_py, ny[2*p+1])\n",
    "\n",
    "        max_py = max_py-1\n",
    "        max_px = max_px-1\n",
    "        min_px = min_px+1\n",
    "        min_py = min_py+1\n",
    "        \n",
    "        if max_py>96 or max_px>96 or min_px<0 or min_py<0:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        x_rotate.append(nx)\n",
    "        y_rotate.append(ny)\n",
    "\n",
    "x_rotate = np.array(x_rotate)\n",
    "y_rotate = np.array(y_rotate)\n",
    "np.random.shuffle(x_rotate)\n",
    "np.random.shuffle(y_rotate)\n",
    "x_rotate = x_rotate[:3*sample]\n",
    "y_rotate = y_rotate[:3*sample]\n",
    "print (x_rotate.shape, y_rotate.shape)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data agumentation 12x\n",
    "x_all = np.ndarray((sample*15, 96, 96), float)\n",
    "y_all = np.ndarray((sample*15, 30), float)\n",
    "\n",
    "# Original\n",
    "x_all[0*sample:1*sample, :, :] = np.copy(x)\n",
    "y_all[0*sample:1*sample, :] = np.copy(y)\n",
    "\n",
    "# Brightness thrice 0.7 1.3 1.6\n",
    "x_all[1*sample:2*sample, :, :] = 0.7*np.copy(x)\n",
    "y_all[1*sample:2*sample, :] = np.copy(y)\n",
    "\n",
    "x_all[2*sample:3*sample, :, :] = np.copy(np.where(1.3*x>1, 1, 1.3*x))\n",
    "y_all[2*sample:3*sample, :] = np.copy(y)\n",
    "\n",
    "x_all[3*sample:4*sample, :, :] = np.copy(np.where(1.6*x>1, 1, 1.6*x))\n",
    "y_all[3*sample:4*sample, :] = np.copy(y)\n",
    "\n",
    "# histogram stretching\n",
    "x_all[4*sample:5*sample, :, :] = np.copy([HistogramStretching(i) for i in x])\n",
    "y_all[4*sample:5*sample, :] = np.copy(y)\n",
    "\n",
    "# gaussian blur\n",
    "x_all[5*sample:6*sample, :, :] = np.copy([cv2.GaussianBlur(i,(5,5),0) for i in x])\n",
    "y_all[5*sample:6*sample, :] = np.copy(y)\n",
    "\n",
    "# mirror + blur + brightness\n",
    "x_all[6*sample:7*sample, :, :] = np.copy([cv2.flip(cv2.GaussianBlur(np.where(1.6*i>1, 1, 1.6*i),(5,5),0),1) for i in x])\n",
    "y_all[6*sample:7*sample, :] = np.copy([mir_y(i) for i in y])\n",
    "\n",
    "# translate\n",
    "x_all[7*sample:11*sample, :, :] = np.copy(x_translate)\n",
    "y_all[7*sample:11*sample, :] = np.copy(y_translate)\n",
    "\n",
    "# rotate\n",
    "x_all[11*sample:14*sample, :, :] = np.copy(x_rotate)\n",
    "y_all[11*sample:14*sample, :] = np.copy(y_rotate)\n",
    "\n",
    "# Mirror\n",
    "for i in range(sample):\n",
    "    x_all[14*sample+i, :, :] = cv2.flip(x[i,:, :], 1)\n",
    "    y_all[14*sample+i, :] = np.copy(mir_y(y[i]))\n",
    "\n",
    "# In[34]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 9216)\n"
     ]
    }
   ],
   "source": [
    "print x_all.shape\n",
    "x_all = x_all[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_all = x_all.reshape(-1,96*96)\n",
    "mean, eg = cv2.PCACompute(x_all, mean=None)\n",
    "x_all = eg[:,:256]\n",
    "x_all = x_all.reshape(-1, 16, 16)\n",
    "print (x_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00802694 -0.00803133 -0.00834015 ... -0.0008761  -0.00111637\n",
      " -0.00098765]\n"
     ]
    }
   ],
   "source": [
    "print eg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all = x_all.reshape(-1,96*96)\n",
    "pca = PCA(copy=True,whiten=False)\n",
    "pca.fit(x_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01305204 0.0128829  0.01275697 ... 0.00794419 0.00819215 0.00824365]\n"
     ]
    }
   ],
   "source": [
    "p = (pca.components_)\n",
    "print p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_all, y_all, test_size=0.2, random_state = 1)\n",
    "# theano and tensorflow have different channel order\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 16, 16, 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], 16, 16, 1)\n",
    "input_shape = (16, 16, 1)\n",
    "    \n",
    "print('x_train shape', x_train.shape)\n",
    "print('x_val shape', x_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[35]:\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32,[None,16,16,1])\n",
    "Y = tf.placeholder(tf.float32,[None,30])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "l2_loss = tf.constant(0.0)\n",
    "\n",
    "#Convolution layer 1\n",
    "w_conv1 = tf.get_variable(\"w_conv1\",shape = [5,5,1,32])\n",
    "b_conv1 = tf.get_variable(\"b_conv1\",shape = [32])\n",
    "z_conv1 = tf.nn.conv2d(X,w_conv1,strides = [1,1,1,1], padding='SAME')+b_conv1\n",
    "print(z_conv1.shape)\n",
    "a_conv1 = tf.nn.relu(z_conv1)\n",
    "max_pool1 = tf.nn.max_pool(a_conv1,ksize=[1,2,2,1],strides=[1,2,2,1], padding='SAME')\n",
    "drp1 = tf.nn.dropout(max_pool1,keep_prob = 0.3)\n",
    "\n",
    "#Convolution layer 2\n",
    "w_conv2 = tf.get_variable(\"w_conv2\",shape = [3,3,32,8])\n",
    "b_conv2 = tf.get_variable(\"b_conv2\",shape = [8])\n",
    "z_conv2 = tf.nn.conv2d(drp1,w_conv2,strides = [1,1,1,1], padding='SAME')+b_conv2\n",
    "print(z_conv2.shape)\n",
    "a_conv2 = tf.nn.relu(z_conv2)\n",
    "max_pool2 = tf.nn.max_pool(a_conv2,ksize=[1,2,2,1],strides=[1,2,2,1], padding='SAME')\n",
    "drp2 = tf.nn.dropout(max_pool2,keep_prob = 0.3)\n",
    "\n",
    "flat1 = tf.reshape(drp2,[-1,128])\n",
    "\n",
    "#Fully connected \n",
    "w_fc1 = tf.get_variable(\"w_fc1\",shape = [128,100])\n",
    "b_fc1 = tf.get_variable(\"b_fc1\",shape = [100])\n",
    "fc1 = tf.matmul(flat1,w_fc1)+b_fc1\n",
    "a_fc1 = tf.nn.relu(fc1)\n",
    "\n",
    "#fully connected 2\n",
    "w_fc2 = tf.get_variable(\"w_fc2\",shape = [100,30])\n",
    "b_fc2 = tf.get_variable(\"b_fc2\",shape = [30])\n",
    "fc2 = tf.matmul(a_fc1,w_fc2)+b_fc2\n",
    "\n",
    "print (Y.shape, fc2.shape)\n",
    "\n",
    "loss = tf.sqrt(tf.reduce_sum((tf.losses.mean_squared_error(Y,fc2))))\n",
    "#loss = tf.reduce_mean(tf.reduce_sum(tf.square(Y - fc2), 1))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(1e-2)\n",
    "\n",
    "# batch normalization in tensorflow requires this extra dependency\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train_step = optimizer.minimize(loss)\n",
    "#train_step = optimizer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "def run_model(session, predict, loss_val, Xd, yd, Xval, yval,\n",
    "              epochs=1, batch_size=64, print_every=100,\n",
    "              training=None, plot_losses=True, save_every=10):\n",
    "    \n",
    "    train_indicies = np.arange(Xd.shape[0])\n",
    "    np.random.shuffle(train_indicies)\n",
    "\n",
    "    training_now = training is not None\n",
    "    \n",
    "    variables = [loss_val, train_step]\n",
    "    if training_now:\n",
    "        variables[-1] = training\n",
    "    \n",
    "    # counter \n",
    "    iter_cnt = 0\n",
    "    for e in range(epochs):\n",
    "        # keep track of losses and accuracy\n",
    "        losses = []\n",
    "        # make sure we iterate over the dataset once\n",
    "        for i in range(int(math.ceil(Xd.shape[0]/batch_size))):\n",
    "            # generate indicies for the batch\n",
    "            start_idx = (i*batch_size)%Xd.shape[0]\n",
    "            idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "            \n",
    "            #print yd[idx[1:3]]\n",
    "            #print idx\n",
    "            \n",
    "            # create a feed dictionary for this batch\n",
    "            feed_dict = {X: Xd[idx],\n",
    "                         Y: yd[idx],\n",
    "                         is_training: training_now }\n",
    "            # get batch size\n",
    "            actual_batch_size = yd[idx].shape[0]\n",
    "            \n",
    "            # have tensorflow compute loss and correct predictions\n",
    "            # and (if given) perform a training step\n",
    "            loss, _ = session.run(variables,feed_dict=feed_dict)\n",
    "            \n",
    "            # aggregate performance stats\n",
    "            losses.append(loss)\n",
    "            \n",
    "            # print every now and then\n",
    "            if training_now and (iter_cnt % print_every) == 0:\n",
    "                print(\"Iteration {0}: with minibatch training loss = {1:.3g}\"                      .format(iter_cnt,loss))\n",
    "            iter_cnt += 1\n",
    "        \n",
    "        \n",
    "        total_loss = np.sum(losses)/(int(math.ceil(Xd.shape[0]/batch_size)))\n",
    "        print(\"Epoch {1}, Overall loss = {0:.3g}\"              .format(total_loss,e+1))\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        if e % save_every == 0:\n",
    "            '''plt.gcf().set_size_inches(10, 4)\n",
    "            \n",
    "            plt.subplot(1,2,1)        \n",
    "            # test a image\n",
    "            print (\"Testing..\")\n",
    "            n_t = np.random.randint(0, Xd.shape[0])\n",
    "            x_t = Xd[n_t]\n",
    "            y_t = session.run(predict, {X:Xd[n_t].reshape(1,96,96,1), is_training:False})\n",
    "            image_x_y(x_t.reshape(96,96), y_t[0])\n",
    "        \n",
    "            plt.subplot(1,2,2)\n",
    "            plt.plot(losses)\n",
    "            plt.grid(True)\n",
    "            plt.title('Epoch {} Loss'.format(e+1))\n",
    "            plt.xlabel('minibatch number')\n",
    "            plt.ylabel('minibatch loss')\n",
    "            plt.show()'''\n",
    "            \n",
    "            # check loss on validation data\n",
    "            feed_dict = {X: Xval,\n",
    "                         Y: yval,\n",
    "                         is_training: False}\n",
    "            loss = session.run(loss_val,feed_dict=feed_dict)\n",
    "            print ('val loss', loss)\n",
    "            \n",
    "            checkpoint_path = os.path.join('/output/', 'model')\n",
    "            saver.save(sess, checkpoint_path)\n",
    "            print(\"model saved to {}\".format(checkpoint_path))\n",
    "            with open('/output/checkpoint', \"w\") as raw:\n",
    "                raw.write('model_checkpoint_path: \"model\"\\nall_model_checkpoint_paths: \"model\"')\n",
    "\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    with tf.device(\"/gpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('Training')\n",
    "        run_model(sess,fc2,loss,x_train,y_train,x_val,y_val,2000,256,50,train_step,True)\n",
    "        #print('Validation')\n",
    "        #run_model(sess,y_out,mean_loss,X_val,y_val,1,64)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
